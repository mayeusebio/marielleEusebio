---
layout: post
title:  "Tracking AR Tags with ar_track_alvar"
date:   2021-02-15 20:29:00 -0700
categories: personal
---

As a part of my senior project on autonomous vehicles, I was tasked with finding out how to detect and track AR tags using a camera. The specific camera we used was the ZED stereo camera, but prior to testing it on that camera that I did not have immediate access to, I wanted to see if it would work on a regular webcam. I found that many resources online were incomplete, outdated, or didn't specify how to use the package with RViz, the 3D visualizer for ROS. I wrote a short guide on how to do so for my other group members, and thought it would be helpful to post here. 

We used the melodic distrubution of ROS which is compatible with Ubuntu 18.0.4 on Linux. 

To start, install the package for your distribution:

{% highlight ruby %}
sudo apt-get install ros-melodic-ar-track-alvar
{% endhighlight %}

Create your first marker. Here I created a marker with the id '123'

{% highlight ruby %}
rosrun ar_track_alvar createMarker 123
{% endhighlight %}

I'm using catkin workspaces which could be read about [here][catkin_ws]. In catkin_ws/src I ran:

{% highlight ruby %}
git clone https://github.com/atomoclast/ar_tag_toolbox
{% endhighlight%}

Back in /catkin_ws I ran
{% highlight ruby %}
catkin_make
{% endhighlight%}

At this point you need to calibrate your camera. I followed [this][cam_calibrate] tutorial on how to calibrate a monocular camera. It would be a slightly different procedure if you were using a stereo camera. 

For the calibration I didn't have access to a larger paper size than a regular 8.5x11 so I simply printed out the checkerboard on that and measured the squares myself. My squares came out to be 0.025m long.

Before you run the calibration program made sure to run the two following commands: (Note: if usb_cam isn't installed already, install it now!)

{% highlight ruby %}
roscore
rosrun usb_cam usb_cam_node
{% endhighlight%}

Now run the calibration program:
{% highlight ruby %}
rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.025 image:=/usb_cam/image_raw camera:=/usb_cam
{% endhighlight%}

Once the GUI is open, move your sheet of paper around in front of the webcam, at different angles and distances. Do this until the calibrate button is highlighted and then after it finishes calibrating save and commit it. Now point the camera at your printed AR tags and run the following: 
(My marker size was 5cm and my webcam was #2 but change if you need)

{% highlight ruby %}
roslaunch ar_tag_toolbox usb_cam.launch cam_id:=2
roslaunch ar_tag_toolbox ar_track_usb_cam.launch marker_size:=5
{% endhighlight%}

This next command will let you see the id of the AR Tag being detected.
{% highlight ruby %}
rostopic echo /ar_pose_marker
{% endhighlight %}

Here's the part most tutorials left out. I needed to see if the camera could see where the tags were in relation to itself. This is done in RViz. To open up Rviz I ran:

{% highlight ruby %}
rosrun rviz rviz
{% endhighlight %}

Once there, make sure to point the camera at an AR tag.
- Add the Camera display to the sidebar, the camera stream should pop up
- Under Global Options, change the Fixed Frame to usb_cam
- Add the TF display to the sidebar
- You can now see the positions of the AR tags in relation to the camera!

<!-- add rviz pictures here -->

[catkin_ws]: http://wiki.ros.org/catkin/Tutorials/create_a_workspace
[cam_calibrate]: http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration#Before_Starting

